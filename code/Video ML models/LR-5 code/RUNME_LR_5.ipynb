{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester for LR-5\n",
    "\n",
    "** Please use python3 to run this code and install all packages that the classifier depends on**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "__authoroftheclassifier__ = 'Sebastien Levy'\n",
    "\n",
    "from processing import ADOS_Data\n",
    "from cross_validation_self import CVP_Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from classifiers import RegClassifier, BinClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func(pred_score, predlabels):\n",
    "    y_true = predlabels\n",
    "    print('Confusion matrix:')\n",
    "    cm = confusion_matrix([1-x for x in y_true], [1-int(x > 0.5) for x in pred_score])\n",
    "    print(cm)\n",
    "    print('Precision: {}'.format(float(cm[0][0])/(cm[0][0]+cm[1][0])))\n",
    "    print('Recall/Sensitivity: {}'.format(float(cm[0][0])/(cm[0][0]+cm[0][1])))\n",
    "    print('Specificity: {}'.format(float(cm[1][1])/(cm[1][1]+cm[1][0])))\n",
    "    print ('class report')\n",
    "    print (classification_report([1-x for x in y_true], [1-int(x > 0.5) for x in pred_score]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODULE = 'm2'\n",
    "\n",
    "FEATURE_SET = ['A3', 'A5', 'B1', 'B2', 'B10']\n",
    "\n",
    "N_FOLD = 10\n",
    "PRED_RATIO = 0.2\n",
    "SCALING_PARAM = 4\n",
    "# Binary or Replacement\n",
    "MISSING_VALUE_STRATEGY = 'Binary'\n",
    "# poly, linear, indicator, interaction_ind, pca_comp\n",
    "PROCESSING_STRATEGY = 'linear'\n",
    "\n",
    "POLY_DEGREE = 2\n",
    "NORMALIZE = True\n",
    "\n",
    "ADOS_FILE = MODULE+\"/data/ados_\"+MODULE+\"_allData.csv\"\n",
    "label_id = \"ASD\"\n",
    "label_age = \"age_months\"\n",
    "label_gender = \"male\"\n",
    "columns_to_delete = [\"Subject.Id\", \"Diagnosis\"]\n",
    "sub_diagnosis_id = [\"social_affect_calc\",\"restricted_repetitive_calc\",\"SA_RRI_total_calc\",\"severity_calc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "#scores = cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello!\n",
      "      A1   A2  A3  A4  A5  A6  A7  A8  B1  B2  ...  D1  D2  D3  D4  E1  E2  \\\n",
      "0      0  1.0   2   0   1   2   0   2   2   1  ...   2   2   0   3   0   1   \n",
      "1      1  0.0   1   2   1   1   0   1   2   1  ...   0   0   0   1   1   0   \n",
      "2      1  2.0   2   1   2   2   2   2   2   2  ...   2   0   0   2   1   2   \n",
      "3      0  1.0   1   0   1   2   0   0   2   2  ...   2   0   0   1   0   1   \n",
      "4      1  0.0   1   2   2   2   0   2   2   1  ...   2   2   0   1   1   0   \n",
      "...   ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
      "1384   0  0.0   2   2   2   2   0   1   2   1  ...   0   0   0   2   0   0   \n",
      "1385   1  2.0   2   2   1   2   1   1   2   2  ...   2   2   0   2   0   0   \n",
      "1386   0  1.0   2   2   2   2   1   1   2   1  ...   2   2   0   2   1   0   \n",
      "1387   0  1.0   2   1   2   1   0   0   2   1  ...   2   2   0   2   1   0   \n",
      "1388   0  1.0   1   1   0   1   0   0   2   1  ...   0   0   0   1   0   0   \n",
      "\n",
      "      E3  age_months  male  ASD  \n",
      "0      2        65.0     1    2  \n",
      "1      1        36.0     0    2  \n",
      "2      2        58.0     0    2  \n",
      "3      1        49.0     1    2  \n",
      "4      1        49.0     0    2  \n",
      "...   ..         ...   ...  ...  \n",
      "1384   0       107.0     0    2  \n",
      "1385   0        79.0     1    2  \n",
      "1386   0        60.0     0    2  \n",
      "1387   0        81.0     1    2  \n",
      "1388   0        62.0     1    1  \n",
      "\n",
      "[1389 rows x 31 columns]\n",
      "gendering\n",
      "male    163\n",
      "dtype: int64\n",
      "printing missing\n",
      "      A1    A2    A3   A4   A5   A6   A7   A8   B1   B2   B3   B4   B5   B6  \\\n",
      "8.0  6.0  13.0  32.0  3.0  5.0  5.0  3.0  4.0  3.0  3.0  3.0  5.0  3.0  3.0   \n",
      "\n",
      "      B7   B8   B9  B10  B11   C1   C2   D1   D2   D3   D4    E1   E2   E3  \\\n",
      "8.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  4.0  3.0  11.0  5.0  6.0   \n",
      "\n",
      "     age_months  male  ASD  \n",
      "8.0         NaN   NaN  NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarth\\Documents\\GitHub\\Autism-Spectrum-Disorder-Detection\\code\\Video ML models\\LR-5 code\\processing.py:75: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self.labels = self[label_id]\n"
     ]
    }
   ],
   "source": [
    "# We import the data\n",
    "data = ADOS_Data.read_csv(ADOS_FILE)\n",
    "sub_diagnosis = data[sub_diagnosis_id]\n",
    "\n",
    "# We drop the columns that are not interesting for us, and the row with no label\n",
    "data.select_good_columns(columns_to_delete+sub_diagnosis_id)\n",
    "\n",
    "print('gendering')\n",
    "print((data[data['ASD'] == 1][['male']]).sum())\n",
    "\n",
    "data.full_preprocessing(NORMALIZE, MISSING_VALUE_STRATEGY, PROCESSING_STRATEGY, [label_age], label_gender, label_id)\n",
    "if FEATURE_SET != []:\n",
    "    data.select_good_columns(FEATURE_SET, keep_the_column=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "1384    2\n",
       "1385    2\n",
       "1386    2\n",
       "1387    2\n",
       "1388    1\n",
       "Name: ASD, Length: 1389, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, data.labels, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import set_option\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using different models to get an idea which model would be good for tuning \n",
    "def GetSimpleModel():\n",
    "    simpleModels = []\n",
    "    simpleModels.append(('Logistic Regression'   , LogisticRegression(max_iter=5000)))\n",
    "    simpleModels.append(('KNeighbors'  , KNeighborsClassifier()))\n",
    "    simpleModels.append(('DecisionTree' , DecisionTreeClassifier()))\n",
    "    simpleModels.append(('Naive Bayes'   , GaussianNB()))\n",
    "    simpleModels.append(('Support Vector Machine'  , SVC(probability=True)))\n",
    "    simpleModels.append(('ADABoost'   , AdaBoostClassifier()))\n",
    "    simpleModels.append(('GradientBoosting'  , GradientBoostingClassifier()))\n",
    "    simpleModels.append(('RandomForest'   , RandomForestClassifier()))\n",
    "\n",
    "    \n",
    "    return simpleModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get cross validation score \n",
    "def BasedLine(x_train, y_train,models):\n",
    "    \n",
    "    num_folds = 5\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits=num_folds)\n",
    "        res = cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(res)\n",
    "        names.append(name)\n",
    "    cv_scores = []\n",
    "    for cv in results:\n",
    "        cv_scores.append(\"{:.4f}\".format(cv.mean()))  \n",
    "\n",
    "    scoreDataFrame = pd.DataFrame({'Model':names, 'Score': cv_scores})\n",
    "    return scoreDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.7678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.7741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.7687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADABoost</td>\n",
       "      <td>0.7993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.7840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.7813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model   Score\n",
       "0     Logistic Regression  0.8038\n",
       "1              KNeighbors  0.7678\n",
       "2            DecisionTree  0.7741\n",
       "3             Naive Bayes  0.7687\n",
       "4  Support Vector Machine  0.7975\n",
       "5                ADABoost  0.7993\n",
       "6        GradientBoosting  0.7840\n",
       "7            RandomForest  0.7813"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = GetSimpleModel()\n",
    "cv_Score=BasedLine(x_train, y_train,models)\n",
    "cv_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, class_weight='balanced')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=0.05, penalty='l2',class_weight='balanced')\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello!\n",
      "         updatedAt  question_set  A3  A5  B10  question3  question4  \\\n",
      "0    6/26/17 16:43             1   8   8    8          8          2   \n",
      "1    6/26/17 16:57             1   0   0    0          0          1   \n",
      "2    6/26/17 17:29             1   0   0    0          0          0   \n",
      "3    6/26/17 17:35             1   2   3    3          1          2   \n",
      "4    6/26/17 18:36             1   0   8    8          8          8   \n",
      "..             ...           ...  ..  ..  ...        ...        ...   \n",
      "462  11/5/17 17:35             1   0   1    1          1          1   \n",
      "463  11/5/17 17:45             1   0   2    2          2          1   \n",
      "464  11/5/17 17:50             1   0   1    1          1          1   \n",
      "465  11/5/17 17:54             1   0   2    2          1          1   \n",
      "466  11/5/17 17:57             1   0   2    2          2          1   \n",
      "\n",
      "     question5  question6  question7  ...  question26  question27  question28  \\\n",
      "0            2          0          3  ...           3           2           3   \n",
      "1            1          8          0  ...           3           0           2   \n",
      "2            0          8          0  ...           0           0           0   \n",
      "3            0          0          1  ...           3           2           3   \n",
      "4            1          0          3  ...           3           2           3   \n",
      "..         ...        ...        ...  ...         ...         ...         ...   \n",
      "462          0          1          1  ...           3           1           1   \n",
      "463          0          1          2  ...           3           2           2   \n",
      "464          0          1          0  ...           1           1           0   \n",
      "465          0          1          0  ...           3           1           1   \n",
      "466          0          0          1  ...           1           2           1   \n",
      "\n",
      "     question29  question30  ASD  age_months  male      createdAt  \\\n",
      "0             2           2    1          60     1  6/26/17 16:43   \n",
      "1             0           0    1          96     1  6/26/17 16:57   \n",
      "2             0           0    1          72     0  6/26/17 17:29   \n",
      "3             0           2    1          48     1  6/26/17 17:35   \n",
      "4             2           3    1          60     1  6/26/17 18:36   \n",
      "..          ...         ...  ...         ...   ...            ...   \n",
      "462           0           1    0          24     0  11/5/17 17:35   \n",
      "463           0           1    0          24     0  11/5/17 17:45   \n",
      "464           0           0    0          24     1  11/5/17 17:50   \n",
      "465           1           1    0          32     0  11/5/17 17:54   \n",
      "466           1           2    0          24     1  11/5/17 17:57   \n",
      "\n",
      "       updatedAt.1  \n",
      "0    6/26/17 16:43  \n",
      "1    6/26/17 16:57  \n",
      "2    6/26/17 17:29  \n",
      "3    6/26/17 17:35  \n",
      "4    6/26/17 18:36  \n",
      "..             ...  \n",
      "462  11/5/17 17:35  \n",
      "463  11/5/17 17:45  \n",
      "464  11/5/17 17:50  \n",
      "465  11/5/17 17:54  \n",
      "466  11/5/17 17:57  \n",
      "\n",
      "[467 rows x 38 columns]\n",
      "printing missing\n",
      "                    updatedAt  question_set    A3    A5   B10  question3  \\\n",
      "0.6375                    NaN           NaN   NaN   NaN   NaN        NaN   \n",
      "0.75                      NaN           NaN   NaN   NaN   NaN        NaN   \n",
      "0.8625                    NaN           NaN   NaN   NaN   NaN        NaN   \n",
      "0.9749999999999999        NaN           NaN   NaN   NaN   NaN        NaN   \n",
      "1                         NaN         467.0  45.0  87.0  87.0      117.0   \n",
      "...                       ...           ...   ...   ...   ...        ...   \n",
      "7/6/17 21:42              1.0           NaN   NaN   NaN   NaN        NaN   \n",
      "7/6/17 21:46              1.0           NaN   NaN   NaN   NaN        NaN   \n",
      "7/7/17 18:32              1.0           NaN   NaN   NaN   NaN        NaN   \n",
      "7/7/17 19:40              1.0           NaN   NaN   NaN   NaN        NaN   \n",
      "7/7/17 19:47              1.0           NaN   NaN   NaN   NaN        NaN   \n",
      "\n",
      "                    question4  question5  question6  question7    B1  \\\n",
      "0.6375                    NaN        NaN        NaN        NaN   NaN   \n",
      "0.75                      NaN        NaN        NaN        NaN   NaN   \n",
      "0.8625                    NaN        NaN        NaN        NaN   NaN   \n",
      "0.9749999999999999        NaN        NaN        NaN        NaN   NaN   \n",
      "1                       135.0       55.0      134.0       88.0  98.0   \n",
      "...                       ...        ...        ...        ...   ...   \n",
      "7/6/17 21:42              NaN        NaN        NaN        NaN   NaN   \n",
      "7/6/17 21:46              NaN        NaN        NaN        NaN   NaN   \n",
      "7/7/17 18:32              NaN        NaN        NaN        NaN   NaN   \n",
      "7/7/17 19:40              NaN        NaN        NaN        NaN   NaN   \n",
      "7/7/17 19:47              NaN        NaN        NaN        NaN   NaN   \n",
      "\n",
      "                    question9  question10  question11  question12  question13  \\\n",
      "0.6375                    NaN         NaN         NaN         NaN         NaN   \n",
      "0.75                      NaN         NaN         NaN         NaN         NaN   \n",
      "0.8625                    NaN         NaN         NaN         NaN         NaN   \n",
      "0.9749999999999999        NaN         NaN         NaN         NaN         NaN   \n",
      "1                        87.0        76.0         2.0        74.0        17.0   \n",
      "...                       ...         ...         ...         ...         ...   \n",
      "7/6/17 21:42              NaN         NaN         NaN         NaN         NaN   \n",
      "7/6/17 21:46              NaN         NaN         NaN         NaN         NaN   \n",
      "7/7/17 18:32              NaN         NaN         NaN         NaN         NaN   \n",
      "7/7/17 19:40              NaN         NaN         NaN         NaN         NaN   \n",
      "7/7/17 19:47              NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "                    question14    B2  question16  question17  question18  \\\n",
      "0.6375                     NaN   NaN         NaN         NaN         NaN   \n",
      "0.75                       NaN   NaN         NaN         NaN         NaN   \n",
      "0.8625                     NaN   NaN         NaN         NaN         NaN   \n",
      "0.9749999999999999         NaN   NaN         NaN         NaN         NaN   \n",
      "1                         11.0  82.0       146.0        23.0         9.0   \n",
      "...                        ...   ...         ...         ...         ...   \n",
      "7/6/17 21:42               NaN   NaN         NaN         NaN         NaN   \n",
      "7/6/17 21:46               NaN   NaN         NaN         NaN         NaN   \n",
      "7/7/17 18:32               NaN   NaN         NaN         NaN         NaN   \n",
      "7/7/17 19:40               NaN   NaN         NaN         NaN         NaN   \n",
      "7/7/17 19:47               NaN   NaN         NaN         NaN         NaN   \n",
      "\n",
      "                    question19  question20  question21  question22  \\\n",
      "0.6375                     NaN         NaN         NaN         NaN   \n",
      "0.75                       NaN         NaN         NaN         NaN   \n",
      "0.8625                     NaN         NaN         NaN         NaN   \n",
      "0.9749999999999999         NaN         NaN         NaN         NaN   \n",
      "1                         59.0        72.0        34.0        23.0   \n",
      "...                        ...         ...         ...         ...   \n",
      "7/6/17 21:42               NaN         NaN         NaN         NaN   \n",
      "7/6/17 21:46               NaN         NaN         NaN         NaN   \n",
      "7/7/17 18:32               NaN         NaN         NaN         NaN   \n",
      "7/7/17 19:40               NaN         NaN         NaN         NaN   \n",
      "7/7/17 19:47               NaN         NaN         NaN         NaN   \n",
      "\n",
      "                    question23  question24  question25  question26  \\\n",
      "0.6375                     NaN         NaN         NaN         NaN   \n",
      "0.75                       NaN         NaN         NaN         NaN   \n",
      "0.8625                     NaN         NaN         NaN         NaN   \n",
      "0.9749999999999999         NaN         NaN         NaN         NaN   \n",
      "1                         60.0        93.0        72.0        22.0   \n",
      "...                        ...         ...         ...         ...   \n",
      "7/6/17 21:42               NaN         NaN         NaN         NaN   \n",
      "7/6/17 21:46               NaN         NaN         NaN         NaN   \n",
      "7/7/17 18:32               NaN         NaN         NaN         NaN   \n",
      "7/7/17 19:40               NaN         NaN         NaN         NaN   \n",
      "7/7/17 19:47               NaN         NaN         NaN         NaN   \n",
      "\n",
      "                    question27  question28  question29  question30    ASD  \\\n",
      "0.6375                     NaN         NaN         NaN         NaN    NaN   \n",
      "0.75                       NaN         NaN         NaN         NaN    NaN   \n",
      "0.8625                     NaN         NaN         NaN         NaN    NaN   \n",
      "0.9749999999999999         NaN         NaN         NaN         NaN    NaN   \n",
      "1                         84.0        35.0        99.0        75.0  343.0   \n",
      "...                        ...         ...         ...         ...    ...   \n",
      "7/6/17 21:42               NaN         NaN         NaN         NaN    NaN   \n",
      "7/6/17 21:46               NaN         NaN         NaN         NaN    NaN   \n",
      "7/7/17 18:32               NaN         NaN         NaN         NaN    NaN   \n",
      "7/7/17 19:40               NaN         NaN         NaN         NaN    NaN   \n",
      "7/7/17 19:47               NaN         NaN         NaN         NaN    NaN   \n",
      "\n",
      "                    age_months  male  createdAt  updatedAt.1  \n",
      "0.6375                     6.0   NaN        NaN          NaN  \n",
      "0.75                      68.0   NaN        NaN          NaN  \n",
      "0.8625                     6.0   NaN        NaN          NaN  \n",
      "0.9749999999999999        45.0   NaN        NaN          NaN  \n",
      "1                          NaN   NaN        NaN          NaN  \n",
      "...                        ...   ...        ...          ...  \n",
      "7/6/17 21:42               NaN   NaN        1.0          1.0  \n",
      "7/6/17 21:46               NaN   NaN        1.0          1.0  \n",
      "7/7/17 18:32               NaN   NaN        1.0          1.0  \n",
      "7/7/17 19:40               NaN   NaN        1.0          1.0  \n",
      "7/7/17 19:47               NaN   NaN        1.0          1.0  \n",
      "\n",
      "[472 rows x 38 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarth\\Documents\\GitHub\\Autism-Spectrum-Disorder-Detection\\code\\Video ML models\\LR-5 code\\processing.py:75: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self.labels = self[label_id]\n"
     ]
    }
   ],
   "source": [
    "FILENAME = \"primary_dataset.csv\"\n",
    "columns_to_delete = ['child_id','scorer_id','video_file'\n",
    "]\n",
    "pred_feat = ADOS_Data.read_csv(FILENAME)\n",
    "ytrue = pred_feat[\"ASD\"]\n",
    "# We drop the columns that are not interesting for us, and the row with no label\n",
    "pred_feat.select_good_columns(columns_to_delete)\n",
    "\n",
    "pred_feat.full_preprocessing(NORMALIZE, MISSING_VALUE_STRATEGY, PROCESSING_STRATEGY, [label_age], label_gender, label_id)\n",
    "if FEATURE_SET != []:\n",
    "    pred_feat.select_good_columns(FEATURE_SET, keep_the_column=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[257  86]\n",
      " [ 38  86]]\n",
      "Precision: 0.8711864406779661\n",
      "Recall/Sensitivity: 0.749271137026239\n",
      "Specificity: 0.6935483870967742\n",
      "class report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.75      0.81       343\n",
      "           1       0.50      0.69      0.58       124\n",
      "\n",
      "    accuracy                           0.73       467\n",
      "   macro avg       0.69      0.72      0.69       467\n",
      "weighted avg       0.77      0.73      0.75       467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_func(list(lr.predict(pred_feat)), ytrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Printing probabilities---\n",
      "[0.52780485 0.25918228 0.21301287]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.00381638 0.16051484 0.83566878]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.29818976 0.44801445 0.25379579]\n",
      "[0.74290631 0.12853337 0.12856032]\n",
      "[0.74290631 0.12853337 0.12856032]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.34839477 0.24533597 0.40626926]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.04498438 0.23327554 0.72174009]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.34839477 0.24533597 0.40626926]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.51927225 0.34681415 0.1339136 ]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.8444396  0.10982723 0.04573316]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.60549815 0.25779504 0.13670681]\n",
      "[0.00381638 0.16051484 0.83566878]\n",
      "[0.35541622 0.26980135 0.37478243]\n",
      "[0.51927225 0.34681415 0.1339136 ]\n",
      "[0.80204264 0.12031205 0.07764531]\n",
      "[0.00134285 0.14425286 0.8544043 ]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.74300034 0.17483993 0.08215973]\n",
      "[0.52780485 0.25918228 0.21301287]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.01060943 0.41055325 0.57883732]\n",
      "[0.08529414 0.24446491 0.67024095]\n",
      "[0.00222181 0.20693589 0.7908423 ]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.0026882  0.15960616 0.83770564]\n",
      "[0.44816842 0.34523366 0.20659792]\n",
      "[0.51927225 0.34681415 0.1339136 ]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.74300034 0.17483993 0.08215973]\n",
      "[0.00760509 0.17679012 0.81560479]\n",
      "[0.03385386 0.26715123 0.69899491]\n",
      "[0.34839477 0.24533597 0.40626926]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.80204264 0.12031205 0.07764531]\n",
      "[0.34839477 0.24533597 0.40626926]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.01077292 0.17740368 0.81182341]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.52789765 0.27944667 0.19265569]\n",
      "[0.34839477 0.24533597 0.40626926]\n",
      "[0.8444396  0.10982723 0.04573316]\n",
      "[0.52780485 0.25918228 0.21301287]\n",
      "[0.04498438 0.23327554 0.72174009]\n",
      "[0.51927225 0.34681415 0.1339136 ]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.13260318 0.40330644 0.46409039]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.04498438 0.23327554 0.72174009]\n",
      "[0.02705398 0.33490392 0.6380421 ]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.78996131 0.16117112 0.04886757]\n",
      "[0.44498677 0.36951856 0.18549467]\n",
      "[0.0401179  0.43058305 0.52929905]\n",
      "[0.13434557 0.4404756  0.42517883]\n",
      "[0.21482112 0.27370122 0.51147766]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.16162994 0.29070053 0.54766953]\n",
      "[0.15545495 0.24625881 0.59828623]\n",
      "[0.0893219  0.2759768  0.63470129]\n",
      "[0.36997182 0.35434638 0.2756818 ]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.08950548 0.29126198 0.61923253]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.78996131 0.16117112 0.04886757]\n",
      "[0.08950548 0.29126198 0.61923253]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.22092176 0.3034279  0.47565035]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.52789765 0.27944667 0.19265569]\n",
      "[0.08529414 0.24446491 0.67024095]\n",
      "[0.17487886 0.349524   0.47559713]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.07161683 0.34711204 0.58127113]\n",
      "[0.1224506  0.28227396 0.59527543]\n",
      "[0.00381638 0.16051484 0.83566878]\n",
      "[0.60010894 0.18785471 0.21203635]\n",
      "[0.36951083 0.38150813 0.24898104]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.34839477 0.24533597 0.40626926]\n",
      "[0.60010894 0.18785471 0.21203635]\n",
      "[0.07161683 0.34711204 0.58127113]\n",
      "[0.36997182 0.35434638 0.2756818 ]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.78996131 0.16117112 0.04886757]\n",
      "[0.00381638 0.16051484 0.83566878]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.13065062 0.34999022 0.51935916]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.74290631 0.12853337 0.12856032]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.74290631 0.12853337 0.12856032]\n",
      "[0.22092176 0.3034279  0.47565035]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.0893219  0.2759768  0.63470129]\n",
      "[0.02705398 0.33490392 0.6380421 ]\n",
      "[0.4419094  0.26980665 0.28828395]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.0579193  0.20639924 0.73568147]\n",
      "[0.60127685 0.27596468 0.12275847]\n",
      "[0.01498133 0.41068016 0.57433851]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.52613327 0.30023564 0.1736311 ]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.44816842 0.34523366 0.20659792]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.00190773 0.14517469 0.85291758]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.35541622 0.26980135 0.37478243]\n",
      "[0.02127222 0.19361189 0.78511589]\n",
      "[0.36866462 0.32754693 0.30378845]\n",
      "[0.51927225 0.34681415 0.1339136 ]\n",
      "[0.78996131 0.16117112 0.04886757]\n",
      "[0.21482112 0.27370122 0.51147766]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.52613327 0.30023564 0.1736311 ]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.52789765 0.27944667 0.19265569]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.60010894 0.18785471 0.21203635]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.6807026  0.18474777 0.13454964]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.21482112 0.27370122 0.51147766]\n",
      "[0.00760509 0.17679012 0.81560479]\n",
      "[0.74300034 0.17483993 0.08215973]\n",
      "[0.10081211 0.39298849 0.5061994 ]\n",
      "[0.52780485 0.25918228 0.21301287]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.0893219  0.2759768  0.63470129]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.29098251 0.32143742 0.38758008]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.52613327 0.30023564 0.1736311 ]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.0893219  0.2759768  0.63470129]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.36866462 0.32754693 0.30378845]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.02408255 0.26827232 0.70764512]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.00988671 0.31259001 0.67752328]\n",
      "[0.52780485 0.25918228 0.21301287]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.08529414 0.24446491 0.67024095]\n",
      "[0.73873637 0.18739515 0.07386847]\n",
      "[0.08529414 0.24446491 0.67024095]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.1224506  0.28227396 0.59527543]\n",
      "[0.52613327 0.30023564 0.1736311 ]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.10880717 0.21430495 0.67688787]\n",
      "[0.07161683 0.34711204 0.58127113]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.04498438 0.23327554 0.72174009]\n",
      "[0.07161683 0.34711204 0.58127113]\n",
      "[0.13260318 0.40330644 0.46409039]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.10880717 0.21430495 0.67688787]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.74290631 0.12853337 0.12856032]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.0320991  0.23497662 0.73292428]\n",
      "[0.35541622 0.26980135 0.37478243]\n",
      "[0.29452591 0.35072791 0.35474617]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.29452591 0.35072791 0.35474617]\n",
      "[0.13260318 0.40330644 0.46409039]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.60127685 0.27596468 0.12275847]\n",
      "[0.0062514  0.22796655 0.76578205]\n",
      "[0.60127685 0.27596468 0.12275847]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.00134285 0.14425286 0.8544043 ]\n",
      "[0.03553907 0.31841378 0.64604715]\n",
      "[0.0184071  0.29838803 0.68320487]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.52613327 0.30023564 0.1736311 ]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.80204264 0.12031205 0.07764531]\n",
      "[0.21482112 0.27370122 0.51147766]\n",
      "[0.2930435  0.39620113 0.31075537]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.60127685 0.27596468 0.12275847]\n",
      "[0.00356026 0.28750109 0.70893865]\n",
      "[0.0062514  0.22796655 0.76578205]\n",
      "[0.60351615 0.20365644 0.19282741]\n",
      "[0.04498438 0.23327554 0.72174009]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.73873637 0.18739515 0.07386847]\n",
      "[0.73873637 0.18739515 0.07386847]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.78996131 0.16117112 0.04886757]\n",
      "[0.8444396  0.10982723 0.04573316]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.60127685 0.27596468 0.12275847]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.07161683 0.34711204 0.58127113]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.67966296 0.19885324 0.1214838 ]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.01741096 0.24858906 0.73399997]\n",
      "[0.0893219  0.2759768  0.63470129]\n",
      "[0.01741096 0.24858906 0.73399997]\n",
      "[0.00222181 0.20693589 0.7908423 ]\n",
      "[0.29098251 0.32143742 0.38758008]\n",
      "[0.52780485 0.25918228 0.21301287]\n",
      "[0.60351615 0.20365644 0.19282741]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.05280473 0.41019323 0.53700203]\n",
      "[0.73873637 0.18739515 0.07386847]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.8444396  0.10982723 0.04573316]\n",
      "[0.36866462 0.32754693 0.30378845]\n",
      "[0.01162201 0.21729379 0.7710842 ]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.72672038 0.20930182 0.0639778 ]\n",
      "[0.10263964 0.43131988 0.46604048]\n",
      "[0.51587738 0.33423334 0.14988928]\n",
      "[0.16160647 0.27597086 0.56242268]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.67134366 0.22300816 0.10564817]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.44100458 0.30570273 0.25329269]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.36951083 0.38150813 0.24898104]\n",
      "[0.6807026  0.18474777 0.13454964]\n",
      "[0.78996131 0.16117112 0.04886757]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.04970072 0.31544542 0.63485386]\n",
      "[0.08529414 0.24446491 0.67024095]\n",
      "[0.44816842 0.34523366 0.20659792]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.74300034 0.17483993 0.08215973]\n",
      "[0.00381638 0.16051484 0.83566878]\n",
      "[0.01077292 0.17740368 0.81182341]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.67966296 0.19885324 0.1214838 ]\n",
      "[0.74300034 0.17483993 0.08215973]\n",
      "[0.01741096 0.24858906 0.73399997]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.0579193  0.20639924 0.73568147]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.60351615 0.20365644 0.19282741]\n",
      "[0.21482112 0.27370122 0.51147766]\n",
      "[0.03796342 0.33291246 0.62912412]\n",
      "[0.36997182 0.35434638 0.2756818 ]\n",
      "[0.17487886 0.349524   0.47559713]\n",
      "[0.36997182 0.35434638 0.2756818 ]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.52789765 0.27944667 0.19265569]\n",
      "[0.74300034 0.17483993 0.08215973]\n",
      "[0.04498438 0.23327554 0.72174009]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.07161683 0.34711204 0.58127113]\n",
      "[0.52780485 0.25918228 0.21301287]\n",
      "[0.36997182 0.35434638 0.2756818 ]\n",
      "[0.0062514  0.22796655 0.76578205]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.29452591 0.35072791 0.35474617]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.4419094  0.26980665 0.28828395]\n",
      "[0.36997182 0.35434638 0.2756818 ]\n",
      "[0.74300034 0.17483993 0.08215973]\n",
      "[0.21482112 0.27370122 0.51147766]\n",
      "[0.22446867 0.35003345 0.42549788]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.36866462 0.32754693 0.30378845]\n",
      "[0.04970072 0.31544542 0.63485386]\n",
      "[0.4419094  0.26980665 0.28828395]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.4419094  0.26980665 0.28828395]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.07326661 0.40317862 0.52355476]\n",
      "[0.01741096 0.24858906 0.73399997]\n",
      "[0.78996131 0.16117112 0.04886757]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.4419094  0.26980665 0.28828395]\n",
      "[0.35838799 0.30888522 0.33272679]\n",
      "[0.04419612 0.25242366 0.70338021]\n",
      "[0.02995643 0.19314569 0.77689788]\n",
      "[0.09290196 0.32589396 0.58120407]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.04758861 0.2801866  0.67222479]\n",
      "[0.36997182 0.35434638 0.2756818 ]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.60351615 0.20365644 0.19282741]\n",
      "[0.0139761  0.31302944 0.67299446]\n",
      "[0.13065062 0.34999022 0.51935916]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.03796342 0.33291246 0.62912412]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.01741096 0.24858906 0.73399997]\n",
      "[0.03796342 0.33291246 0.62912412]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.10880717 0.21430495 0.67688787]\n",
      "[0.29452591 0.35072791 0.35474617]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.2930435  0.39620113 0.31075537]\n",
      "[0.78996131 0.16117112 0.04886757]\n",
      "[0.10880717 0.21430495 0.67688787]\n",
      "[0.0579193  0.20639924 0.73568147]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.87484337 0.09865102 0.02650561]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.67134366 0.22300816 0.10564817]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.8444396  0.10982723 0.04573316]\n",
      "[0.52789765 0.27944667 0.19265569]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.74300034 0.17483993 0.08215973]\n",
      "[0.52780485 0.25918228 0.21301287]\n",
      "[0.00885674 0.22879324 0.76235002]\n",
      "[0.08529414 0.24446491 0.67024095]\n",
      "[0.52789765 0.27944667 0.19265569]\n",
      "[0.29452591 0.35072791 0.35474617]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.13260318 0.40330644 0.46409039]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.52789765 0.27944667 0.19265569]\n",
      "[0.09290196 0.32589396 0.58120407]\n",
      "[0.01162201 0.21729379 0.7710842 ]\n",
      "[0.22092176 0.3034279  0.47565035]\n",
      "[0.29452591 0.35072791 0.35474617]\n",
      "[0.4419094  0.26980665 0.28828395]\n",
      "[0.35541622 0.26980135 0.37478243]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.00381638 0.16051484 0.83566878]\n",
      "[0.08529414 0.24446491 0.67024095]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.67966296 0.19885324 0.1214838 ]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.00381638 0.16051484 0.83566878]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.22092176 0.3034279  0.47565035]\n",
      "[0.44482415 0.29276896 0.26240688]\n",
      "[0.01077292 0.17740368 0.81182341]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.29452591 0.35072791 0.35474617]\n",
      "[0.6807026  0.18474777 0.13454964]\n",
      "[0.80204264 0.12031205 0.07764531]\n",
      "[0.52780485 0.25918228 0.21301287]\n",
      "[0.03796342 0.33291246 0.62912412]\n",
      "[0.51927225 0.34681415 0.1339136 ]\n",
      "[0.07161683 0.34711204 0.58127113]\n",
      "[0.8444396  0.10982723 0.04573316]\n",
      "[0.10263964 0.43131988 0.46604048]\n",
      "[0.29098251 0.32143742 0.38758008]\n",
      "[0.0339972  0.28256069 0.68344211]\n",
      "[0.60351615 0.20365644 0.19282741]\n",
      "[0.10263964 0.43131988 0.46604048]\n",
      "[0.60127685 0.27596468 0.12275847]\n",
      "[0.4419094  0.26980665 0.28828395]\n",
      "[0.52780485 0.25918228 0.21301287]\n",
      "[0.28590134 0.29297358 0.42112508]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.60351615 0.20365644 0.19282741]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.27370194 0.27207695 0.45422111]\n",
      "[0.74300034 0.17483993 0.08215973]\n",
      "[0.22092176 0.3034279  0.47565035]\n",
      "[0.36866462 0.32754693 0.30378845]\n",
      "[0.29098251 0.32143742 0.38758008]\n",
      "[0.60351615 0.20365644 0.19282741]\n",
      "[0.60351615 0.20365644 0.19282741]\n",
      "[0.43710277 0.24756298 0.31533425]\n",
      "[0.27370194 0.27207695 0.45422111]\n",
      "[0.80204264 0.12031205 0.07764531]\n",
      "[0.29098251 0.32143742 0.38758008]\n",
      "[0.13000969 0.36680874 0.50318157]\n",
      "[0.60351615 0.20365644 0.19282741]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.34839477 0.24533597 0.40626926]\n",
      "[0.60351615 0.20365644 0.19282741]\n",
      "[0.04739664 0.26495513 0.68764823]\n",
      "[0.44816842 0.34523366 0.20659792]\n",
      "[0.01642985 0.21760831 0.76596184]\n",
      "[0.1781326  0.38379594 0.43807146]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.00541541 0.16135068 0.83323392]\n",
      "[0.01741096 0.24858906 0.73399997]\n",
      "[0.22092176 0.3034279  0.47565035]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.67966296 0.19885324 0.1214838 ]\n",
      "[0.1781326  0.38379594 0.43807146]\n",
      "[0.4419094  0.26980665 0.28828395]\n",
      "[0.01523986 0.17778128 0.80697886]\n",
      "[0.52613327 0.30023564 0.1736311 ]\n",
      "[0.67966296 0.19885324 0.1214838 ]\n",
      "[0.03796342 0.33291246 0.62912412]\n",
      "[0.52789765 0.27944667 0.19265569]\n",
      "[0.29452591 0.35072791 0.35474617]\n",
      "[0.02454766 0.24828188 0.72717046]\n",
      "[0.29098251 0.32143742 0.38758008]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.73873637 0.18739515 0.07386847]\n",
      "[0.12688755 0.31531611 0.55779635]\n",
      "[0.1781326  0.38379594 0.43807146]\n",
      "---End of Printing Probabilities---\n"
     ]
    }
   ],
   "source": [
    "print(\"---Printing probabilities---\")\n",
    "LogisticProbabilities = (lr.predict_proba(pred_feat))\n",
    "for line in LogisticProbabilities:\n",
    "    print(line)\n",
    "print(\"---End of Printing Probabilities---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 2, 2, 1, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(list(lr.predict(pred_feat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = list(zip(LogisticProbabilities, list(lr.predict(pred_feat))))\n",
    "with open('results_lr_5.csv', 'w') as f:\n",
    "    for i in range(len(l)):\n",
    "        f.write(str(l[i])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
